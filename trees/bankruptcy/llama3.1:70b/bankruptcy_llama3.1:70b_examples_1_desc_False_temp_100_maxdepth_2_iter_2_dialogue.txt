Based on the features you provided, I will build a decision tree classifier with a maximum depth of 2 to classify whether a company went bankrupt or not.

Here is the decision tree:

|--- Retained Earnings/Total Assets <= -0.15
||--- class: Bankrupt
|--- Retained Earnings/Total Assets > -0.15
||--- Working Capital/Total Assets <= 0.25
|||--- class: Bankrupt
||--- Working Capital/Total Assets > 0.25
|||--- class: Not Bankrupt

Here's a brief explanation of the decision tree:

* The first feature considered is Retained Earnings/Total Assets, which indicates a company's ability to generate profits and reinvest them in the business. A low value (<= -0.15) suggests that the company has struggled to generate profits or has been using its assets inefficiently, leading to a higher risk of bankruptcy.
* For companies with Retained Earnings/Total Assets > -0.15, the next feature considered is Working Capital/Total Assets, which measures a company's liquidity and ability to meet short-term obligations. A low value (<= 0.25) suggests that the company may struggle to pay its debts or meet its financial obligations, leading to a higher risk of bankruptcy.
* Companies with both Retained Earnings/Total Assets > -0.15 and Working Capital/Total Assets > 0.25 are considered less likely to go bankrupt.

Please note that this decision tree is not necessarily optimal and may not generalize well to new data. The choice of features, threshold values, and maximum depth were determined based on a simple analysis, but a more thorough evaluation using techniques such as cross-validation and feature engineering may be necessary for better results.


#########################


Here is the Python function that implements the decision tree:

```python
def predict(X: dict):
    nodes = 2 * [None]
    nodes[0] = X["RE/TA"] <= -0.15
    nodes[1] = X["WC/TA"] <= 0.25
    
    if not nodes[0]:
        if nodes[1]:
            prediction = 1
        else:
            prediction = 0
    else:
        prediction = 1

    # Convert boolean values to integers (1 for True, 0 for False)
    nodes = [int(node) for node in nodes]
    
    return prediction, nodes
```

This function takes a dictionary `X` as input, where the keys are the feature names and the values are the corresponding feature values. It uses these feature values to make predictions based on the decision tree.

Note that I've assumed some threshold values (-0.15 for "RE/TA" and 0.25 for "WC/TA") which may not be optimal. These thresholds can be adjusted based on further analysis of the data.

Also, I've used the `int()` function to convert the boolean values in the `nodes` list to integers (1 for True, 0 for False), as per your requirement.