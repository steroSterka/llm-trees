I'll build a decision tree using the most important features. Since I don't have access to the actual data, I'll make some assumptions about the relationships between the features and the outcome of the labor negotiations (good or bad). Please note that this is a simplified example, and in practice, you would use a more robust method to select the most important features.

After analyzing the features, I've selected the top 5 most relevant ones:

1. Wage increase in first year of contract (2 to 7)
2. Duration of agreement (1 to 7)
3. Cost of living adjustment (none / temporary cost of living adjustment formula / total compensation adjustment)
4. Number of paid vacation days (below average / average / generous)
5. Employer's contribution towards the health plan (none / half / full)

Here's a possible decision tree:

|--- Wage increase in first year of contract <= 4
||--- Duration of agreement <= 3
|||--- class: bad
||--- Duration of agreement > 3
|||--- Cost of living adjustment = none
||||--- class: bad
||||--- Cost of living adjustment != none
|||||--- class: good
|--- Wage increase in first year of contract > 4
||--- Number of paid vacation days = generous
|||--- Employer's contribution towards the health plan = full
||||--- class: good
||||--- Employer's contribution towards the health plan != full
|||||--- class: bad
||--- Number of paid vacation days != generous
|||--- class: bad

This decision tree can be interpreted as follows:

* If the wage increase in the first year is 4% or less, and the duration of the agreement is 3 years or less, the outcome is likely to be bad.
* If the wage increase in the first year is more than 4%, and the number of paid vacation days is generous (i.e., above average), and the employer's contribution towards the health plan is full, the outcome is likely to be good.

Please note that this is a simplified example and may not reflect the actual relationships between the features and the outcome. In practice, you would use more robust methods, such as cross-validation and feature selection techniques, to build a more accurate decision tree.


#########################


Here's the function that implements the decision tree:

```python
def predict(X: dict):
    nodes = 7 * [None]
    
    # Wage increase in first year of contract <= 4
    nodes[0] = X["wage increase first year"] <= 4
    
    # Duration of agreement <= 3
    nodes[1] = X["duration"] <= 3
    
    # Cost of living adjustment is none
    nodes[2] = X["cost of living adjustment"] == "none"
    
    # Number of paid vacation days is generous (gnr)
    nodes[3] = X["vacation"] == "gnr"
    
    # Employer's contribution towards the health plan is full
    nodes[4] = X["contribution to health plan"] == "full"
    
    if not nodes[0]:
        prediction = 1 if (nodes[3] and nodes[4]) else 0
        nodes[5] = False
        nodes[6] = False
    elif not nodes[1]:
        prediction = 1 if not nodes[2] else 0
        nodes[5] = True
        nodes[6] = not nodes[2]
    else:
        prediction = 0
        nodes[5] = True
        nodes[6] = True
    
    return prediction, [int(node) for node in nodes[:7]]
```

This function takes a dictionary `X` with the input features as keys and their corresponding values. The function implements the decision tree using the selected features: "wage increase first year", "duration", "cost of living adjustment", "vacation", and "contribution to health plan".

The `nodes` list stores the truth values of the inner nodes, which are used to determine the prediction. The prediction is then returned along with the `nodes` list.

Note that I've assumed some threshold values for the features based on the provided description. If you need to adjust these thresholds or modify the decision tree, please let me know!